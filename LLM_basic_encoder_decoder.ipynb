{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1kDn4YZtlEYLcZ6f0-egtbKFotLUERjht",
      "authorship_tag": "ABX9TyOPZhpJbphVLyGUCbNcud2O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArielKatzir/LLM_EncoderDecoder_Translator_PyTorch/blob/master/LLM_basic_encoder_decoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Small Scale Encoder Decoder LLM Translating English to Italian\n",
        "### Made from scratch - i.e. no Huggingface.Transformers. Only PyTorch"
      ],
      "metadata": {
        "id": "PsTooFVQo1H5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install sacrebleu"
      ],
      "metadata": {
        "id": "EDip-r0vOsSf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a600bd73-adc1-439c-b5b4-60449fccb502"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2.0.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-3.2.0 sacrebleu-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "First we download and load the data"
      ],
      "metadata": {
        "id": "wif39fEgZ4dD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "import sacrebleu\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sentencepiece as spm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.amp import autocast, GradScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# data downloaded from https://tatoeba.org/en/downloads\n",
        "raw_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/english_italian.tsv', sep='\\t', on_bad_lines='skip')\n",
        "raw_df.shape, raw_df.head(1)"
      ],
      "metadata": {
        "id": "ChEGayLkaBjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d657c2-6995-4995-e759-3e3bc0476a0c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((681865, 4),\n",
              "    1276    Let's try something.  565618      Proviamo qualcosa!\n",
              " 0  1277  I have to go to sleep.  4369.0  Devo andare a dormire.)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokanise - we will need to train the tokaniser first. It is in the format of a .txt file where one sentance is in english and the line after will have the translation. For this ill need to use maybe 100k samples."
      ],
      "metadata": {
        "id": "9L357rS9dADM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t_english = np.array(raw_df[raw_df.columns[1]])\n",
        "t_italian = np.array(raw_df[raw_df.columns[3]])\n",
        "\n",
        "# make random boolean mask\n",
        "mask = np.random.rand(t_english.shape[0]) > 0.95\n",
        "\n",
        "# Apply mask to get valid indices\n",
        "masked_indices = np.where(mask)[0]\n",
        "assert len(t_english) == len(t_italian), \"Mismatched lengths!\"\n",
        "\n",
        "t_eng_sample = t_english[masked_indices][:30000] # just to have a round number\n",
        "t_ita_sample = t_italian[masked_indices][:30000]\n",
        "\n",
        "t_eng_sample.shape, t_ita_sample.shape"
      ],
      "metadata": {
        "id": "u-zDs-M4dD88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac18d31a-47a7-4e5d-90b5-0cced9de4d1a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30000,), (30000,))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save txt file for tokanizer training data\n",
        "with open(\"english_italian_tokanizer.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for en, it in zip(t_eng_sample, t_ita_sample):\n",
        "        f.write(en.strip() + \"\\n\")\n",
        "        f.write(it.strip() + \"\\n\\n\")"
      ],
      "metadata": {
        "id": "ST0NfTVrmcqq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train byte pair encoding (bpe) which learns tokens better by breaking\n",
        "# down words into relevant chunks. Vocab size 8000 is good for around 150000\n",
        "spm.SentencePieceTrainer.train(\n",
        "    input='english_italian_tokanizer.txt',\n",
        "    model_prefix='bpe',\n",
        "    vocab_size=8000,\n",
        "    character_coverage=1.0,   # use 0.9995 for non-Latin languages\n",
        "    model_type='bpe',          # or 'unigram', 'word', 'char'\n",
        "    pad_id=0, pad_piece='<pad>',\n",
        "    unk_id=1, unk_piece='<unk>',\n",
        "    bos_id=2, bos_piece='<s>',\n",
        "    eos_id=3, eos_piece='</s>'\n",
        ")"
      ],
      "metadata": {
        "id": "fkJDeX_ho2TV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load tokaniser and try it out\n",
        "tokenizer = spm.SentencePieceProcessor()\n",
        "tokenizer.load(\"bpe.model\")\n",
        "# english and italian\n",
        "encoded = tokenizer.encode(\"ciao come stai? And also, how are you?\", out_type=int)\n",
        "encoded"
      ],
      "metadata": {
        "id": "uBJITMkrqP4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a05a06e-8d02-4d4b-ab11-f7142bed07cf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 5206, 337, 1762, 7912, 1238, 3415, 7917, 1036, 199, 40, 7912]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets take our training data sample. Make it small coz we dont have much GPU power."
      ],
      "metadata": {
        "id": "takLrOJGygRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 50\n",
        "sos_id = tokenizer.piece_to_id('<s>')\n",
        "eos_id = tokenizer.piece_to_id('</s>')\n",
        "pad_id = tokenizer.piece_to_id('<pad>')\n",
        "unk_id = tokenizer.unk_id()\n",
        "encoded = tokenizer.encode(\"ciao come stai? And also, how are you?\", out_type=int)\n",
        "encoded"
      ],
      "metadata": {
        "id": "5j8P2tQkyrNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13d0498a-f321-45de-ea44-22ed7e746922"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 5206, 337, 1762, 7912, 1238, 3415, 7917, 1036, 199, 40, 7912]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a class where we can fetch tokenized input/target pair - includes padding."
      ],
      "metadata": {
        "id": "e2L-vjBCLm0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslationDataset(Dataset):\n",
        "  def __init__(self, src_sentences, tgt_sentences, tokenizer, max_len):\n",
        "    self.src = src_sentences\n",
        "    self.tgt = tgt_sentences\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.src)\n",
        "\n",
        "  # this method is required for a Dataset subclass\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    # encode english and italian indices from the training data\n",
        "    src_ids = self.tokenizer.encode(self.src[idx], out_type=int)\n",
        "    tgt_ids = self.tokenizer.encode(self.tgt[idx], out_type=int)\n",
        "\n",
        "    # ensure max length is enforced for consistancy\n",
        "    src_ids = src_ids[:self.max_len]\n",
        "\n",
        "    # here we must to add start and end of sentance to tell the model when to\n",
        "    # start and stop generating output\n",
        "    tgt_ids = [sos_id] + tgt_ids[:self.max_len - 2] + [eos_id]\n",
        "\n",
        "    # add padding to ensure both input and output have exactly max_length context\n",
        "    src_ids += [pad_id] * (self.max_len - len(src_ids))\n",
        "    tgt_ids += [pad_id] * (self.max_len - len(tgt_ids))\n",
        "\n",
        "    return {\n",
        "        'src': torch.tensor(src_ids, dtype=torch.long),\n",
        "        'tgt': torch.tensor(tgt_ids, dtype=torch.long)\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "B1SMofQhGNMP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now need to define the layers."
      ],
      "metadata": {
        "id": "qC-cuXf6LbvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(nn.Module):\n",
        "  def __init__(self, vocab_size, d_model, max_len):\n",
        "    super().__init__()\n",
        "    self.token_embed = nn.Embedding(vocab_size, d_model)\n",
        "    self.pos_embed = nn.Embedding(max_len, d_model)\n",
        "  def forward(self, x):\n",
        "    positions = torch.arange(0, x.size(1), device=x.device).unsqueeze(0)\n",
        "    return self.token_embed(x) + self.pos_embed(positions)"
      ],
      "metadata": {
        "id": "0FgIdO1ILkNV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "  def __init__(self, d_model, heads):\n",
        "    super().__init__()\n",
        "\n",
        "    # creates Q,K,V projected inputs and returns the attention matrix\n",
        "    self.attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=heads, batch_first=True)\n",
        "\n",
        "    self.ln1 = nn.LayerNorm(d_model)\n",
        "    # fast forward\n",
        "    self.ffn = nn.Sequential(\n",
        "        nn.Linear(d_model, 4*d_model),\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(0.1),\n",
        "        nn.Linear(4*d_model, d_model),\n",
        "        nn.Dropout(0.1)\n",
        "    )\n",
        "    self.ln2 = nn.LayerNorm(d_model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # input is of dim: (B,T,d_model)\n",
        "    B, T, _ = x.shape\n",
        "\n",
        "    # No masking is needed here because its the encoder\n",
        "\n",
        "    attn_output, _ = self.attn(x, x, x)\n",
        "    x = self.ln1(x + attn_output)\n",
        "    x = self.ln2(x + self.ffn(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "uW2shvOLOfom"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self, d_model, heads):\n",
        "    super().__init__()\n",
        "    # this is attention of the decoder input, it only looks at the previous tokens\n",
        "    self.self_attn = nn.MultiheadAttention(d_model, heads, batch_first=True)\n",
        "\n",
        "    # this is attention which includes information from the decoder, which gathered\n",
        "    # information from the entire sequence. Basically remembers.\n",
        "    self.cross_attn = nn.MultiheadAttention(d_model, heads, batch_first=True)\n",
        "\n",
        "    self.ln1 = nn.LayerNorm(d_model)\n",
        "    self.ln2 = nn.LayerNorm(d_model)\n",
        "    self.ln3 = nn.LayerNorm(d_model)\n",
        "\n",
        "    self.ffn = nn.Sequential(\n",
        "        nn.Linear(d_model, 4 * d_model),\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(0.1),\n",
        "        nn.Linear(4 * d_model, d_model),\n",
        "        nn.Dropout(0.1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x, memory, tgt_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
        "    # notice here that every time we normalise the layer we do it on the residual connection.\n",
        "\n",
        "    self.attn_output, _ = self.self_attn(x, x, x, attn_mask=tgt_mask, key_padding_mask=tgt_key_padding_mask)\n",
        "    x = self.ln1(x + self.attn_output)\n",
        "\n",
        "    cross_attn_output, _ = self.cross_attn(x, memory, memory, key_padding_mask=memory_key_padding_mask)\n",
        "    x = self.ln2(x + cross_attn_output)\n",
        "\n",
        "    x = self.ln3(x + self.ffn(x))\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "7KY_EmrdVe3I"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now wrap all these three blocks into one wrapper"
      ],
      "metadata": {
        "id": "tuy_zS3xksRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoderModel(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, n_heads, max_len, num_blocks):\n",
        "        super().__init__()\n",
        "\n",
        "        # create embeddings for encoder and decoder\n",
        "        self.src_embed = Embeddings(vocab_size, d_model, max_len)\n",
        "        self.tgt_embed = Embeddings(vocab_size, d_model, max_len)\n",
        "\n",
        "        # lists of encoder and decoder blocks\n",
        "        self.encoder_blocks = nn.ModuleList([\n",
        "            EncoderBlock(d_model, n_heads) for _ in range(num_blocks)\n",
        "        ])\n",
        "\n",
        "        self.decoder_blocks = nn.ModuleList([\n",
        "            DecoderBlock(d_model, n_heads) for _ in range(num_blocks)\n",
        "        ])\n",
        "\n",
        "        self.output_layer = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt, tgt_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
        "        # src: [B, S]\n",
        "        # tgt: [B, T]\n",
        "\n",
        "        # make the embeddings from the tokens\n",
        "        src_embedded = self.src_embed(src)  # [B, S, d_model]\n",
        "        tgt_embedded = self.tgt_embed(tgt)  # [B, T, d_model]\n",
        "\n",
        "        # pass through the encoder stack in series\n",
        "        memory = src_embedded\n",
        "        for block in self.encoder_blocks:\n",
        "            memory = block(memory)  # [B, S, d_model]\n",
        "\n",
        "        # pass through decoder stack\n",
        "        x = tgt_embedded\n",
        "        for block in self.decoder_blocks:\n",
        "            x = block(x, memory, tgt_mask, tgt_key_padding_mask, memory_key_padding_mask)\n",
        "\n",
        "        logits = self.output_layer(x)\n",
        "\n",
        "        # Final output projection is done inside each decoder block\n",
        "        return logits"
      ],
      "metadata": {
        "id": "HUISbj2Gk0bO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK cool! Now the model architecture is finished. We have an encoder and a decoder model. We can start building the training loop. The idea is that we feed a source sentance in english to the encoder, the encoder comes up with a contextual memory matrix, which feeds into the decoder as input along with the original input, and the decoder, hopfully, comes up with a logits distribution which can help choose a translation. For example:\n",
        "- src: \"How are you?\"\n",
        "- DIn: \"<'bos'> come stai?\"\n",
        "- Dout: \"come stai? <'eos'>\""
      ],
      "metadata": {
        "id": "YIYqgb9qoMit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# config\n",
        "vocab_size = 8000       # should be enough\n",
        "d_model = 128          # embedding size - needs to be divisible by n_heads\n",
        "n_heads = 8           # 4 attention heads\n",
        "max_len = 50           # max sequence length - i didnt see anything which should get anywhere near this but safety\n",
        "num_blocks = 4        # transformer blocks\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "\n",
        "# but do we even have a GPU???\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "id": "QXBDxYw4MrGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b196011-ae0b-4fde-ae18-979050d2173d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# init the model\n",
        "model = EncoderDecoderModel(\n",
        "    vocab_size=vocab_size,\n",
        "    d_model=d_model,\n",
        "    n_heads=n_heads,\n",
        "    max_len=max_len,\n",
        "    num_blocks=num_blocks\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "SAmzW0j8phNS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Trainable parameters: {num_params:,}\")"
      ],
      "metadata": {
        "id": "Moyi-sctsVCh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "488e813f-401b-48d7-c86b-88403aa46e33"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 4,944,192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch random data - ensure small scale - colab gpu weakkk"
      ],
      "metadata": {
        "id": "-jYWtnXstvOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ensure each sentance is a string (some arent somehow)\n",
        "all_english = np.array([str(s) for s in t_english.tolist()])\n",
        "all_italian = np.array([str(s) for s in t_italian.tolist()])\n",
        "\n",
        "# randomly make a ~5% bool mask and then cap to 30k for training\n",
        "mask = np.random.rand(len(all_english)) > 0.5\n",
        "candidate_idxs = np.where(mask)[0]\n",
        "train_idxs     = candidate_idxs[:30000]\n",
        "\n",
        "train_en = all_english[train_idxs]\n",
        "train_it = all_italian[train_idxs]\n",
        "\n",
        "# everything else → hold‐out pool\n",
        "remaining_idxs = np.setdiff1d(np.arange(len(all_english)), train_idxs)\n",
        "\n",
        "# split remaining into val and test - 50/50\n",
        "val_idxs, test_idxs = train_test_split(\n",
        "    remaining_idxs,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "max_test_val = 5000\n",
        "\n",
        "val_en  = all_english[val_idxs][:max_test_val]\n",
        "val_it  = all_italian[val_idxs][:max_test_val]\n",
        "test_en = all_english[test_idxs][:max_test_val]\n",
        "test_it = all_italian[test_idxs][:max_test_val]\n",
        "\n",
        "train_en.shape, train_it.shape, val_en.shape, val_en.shape, test_en.shape, test_en.shape"
      ],
      "metadata": {
        "id": "8eqY10kjypUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af0e920f-345f-4ff6-c77f-e45633b168f4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30000,), (30000,), (5000,), (5000,), (5000,), (5000,))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# init the data loader\n",
        "train_dataset = TranslationDataset(\n",
        "    src_sentences=train_en,\n",
        "    tgt_sentences=train_it,\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        ")"
      ],
      "metadata": {
        "id": "6m5gDVN7tIFD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a data loader\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True   #  drops last incomplete batch\n",
        ")"
      ],
      "metadata": {
        "id": "Gw8LQR-wuJl-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# just a function to make a triangle mask for the decoder\n",
        "def generate_causal_mask(size: int, device: torch.device = None):\n",
        "    # returns a matrix mask with -inf above the diagonal, 0.0 on and below\n",
        "    mask = torch.triu(torch.full((size, size), float('-inf')), diagonal=1)\n",
        "    if device is not None:\n",
        "        mask = mask.to(device)\n",
        "    return mask"
      ],
      "metadata": {
        "id": "jvdl-6vfvttK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss(ignore_index=pad_id)  # ignores <pad> tokens\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "training_losses = []\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    model.train() # enter training mode\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        src = batch['src'].to(device)  # [B, S]\n",
        "        tgt = batch['tgt'].to(device)  # [B, T]\n",
        "\n",
        "        tgt_input = tgt[:, :-1]  # remove last token for decoder input\n",
        "        tgt_output = tgt[:, 1:]  # remove first token for decoder output\n",
        "\n",
        "        # generate masks for decoder and pads\n",
        "        tgt_mask = generate_causal_mask(tgt_input.size(1), device)\n",
        "        tgt_key_padding_mask = (tgt_input == pad_id)\n",
        "        memory_key_padding_mask = (src == pad_id)\n",
        "\n",
        "        # pass in the network\n",
        "        logits = model(src, tgt_input,\n",
        "                       tgt_mask=tgt_mask,\n",
        "                       tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "                       memory_key_padding_mask=memory_key_padding_mask)\n",
        "\n",
        "        # reshape for loss because CrossEntropyLoss expects a plattend B*T rather than (B,T,vocab)\n",
        "        logits = logits.reshape(-1, vocab_size)        # [(B*T), vocab]\n",
        "        tgt_output = tgt_output.reshape(-1)            # [(B*T)]\n",
        "\n",
        "        loss = loss_fn(logits, tgt_output)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}: loss = {avg_loss:.4f}\")\n",
        "    training_losses.append(avg_loss)\n"
      ],
      "metadata": {
        "id": "rkrXMjvFssX8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dac9e66-c9a4-462d-d94f-3b07e58a8b87"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss = 6.0486\n",
            "Epoch 2: loss = 5.0227\n",
            "Epoch 3: loss = 4.4874\n",
            "Epoch 4: loss = 4.0570\n",
            "Epoch 5: loss = 3.6889\n",
            "Epoch 6: loss = 3.3672\n",
            "Epoch 7: loss = 3.0799\n",
            "Epoch 8: loss = 2.8268\n",
            "Epoch 9: loss = 2.5964\n",
            "Epoch 10: loss = 2.3882\n",
            "Epoch 11: loss = 2.1980\n",
            "Epoch 12: loss = 2.0283\n",
            "Epoch 13: loss = 1.8704\n",
            "Epoch 14: loss = 1.7310\n",
            "Epoch 15: loss = 1.6017\n",
            "Epoch 16: loss = 1.4850\n",
            "Epoch 17: loss = 1.3743\n",
            "Epoch 18: loss = 1.2762\n",
            "Epoch 19: loss = 1.1854\n",
            "Epoch 20: loss = 1.0988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot loss over time\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, len(training_losses)+1), training_losses, marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss over Epochs')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DWnVfVc0YJy-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "881d369d-dc6f-4710-bbd9-4450003eac78"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the loss goes down, and can go down more. But alone it might not mean much.\n",
        "Ideally, we should have added validation code in the main loop. But for educational purposes i want to look at the results of this model and how it performs, and later we do it again with validation to see the effect it has.  \n",
        "\n",
        "# Inference (Greedy Decoding) - aka Autoregressively decoding\n",
        "So now we only have the source english.\n",
        "You need to generate the target tokens one by one:\n",
        "Run the encoder on src → get memory.\n",
        "\n",
        "Initialize your decoder input with just <\"sos\"> char.\n",
        "\n",
        "Run the decoder on that to get logits → pick the highest-score token → append to your sequence.\n",
        "\n",
        "Repeat: feed this longer sequence back into the decoder (with the same memory) to get the next token.\n",
        "\n",
        "Stop when you generate <\"eos\"> or reach max_len.\n",
        "\n",
        "Because this is a loop (“for step in 1…max_len”), and because you have to interleave model.forward calls with argmax and append, we wrap it up in a separate translate() function."
      ],
      "metadata": {
        "id": "yfjTF_yHIZ4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(model, src_sentence: str, tokenizer, max_len: int):\n",
        "    # pass an input into the trained network to get the translation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # tokanise the source sentence, add padding if needed, move to gpu\n",
        "        src_ids = tokenizer.encode(src_sentence, out_type=int)\n",
        "        src_ids = src_ids[:max_len] + [pad_id] * (max_len - len(src_ids))\n",
        "        src_tensor = torch.tensor([src_ids], device=device)\n",
        "\n",
        "        # create embedding, pass in the encoder.\n",
        "        memory = model.src_embed(src_tensor)\n",
        "        for blk in model.encoder_blocks:\n",
        "            memory = blk(memory)\n",
        "\n",
        "        # decode repeatidly on generated outputs until the <eos> is reached\n",
        "        tgt_ids = [sos_id]\n",
        "\n",
        "        # to max sequence length\n",
        "        for _ in range(max_len):\n",
        "\n",
        "            # build decoder input with paddings, move to gpu\n",
        "            decoder_input = tgt_ids + [pad_id] * (max_len - len(tgt_ids))\n",
        "            tgt_tensor = torch.tensor([decoder_input], device=device)\n",
        "\n",
        "            # apply all decoder blocks\n",
        "            x = model.tgt_embed(tgt_tensor)\n",
        "            tgt_mask = generate_causal_mask(x.size(1), device)\n",
        "            for blk in model.decoder_blocks:\n",
        "                x = blk(x, memory,\n",
        "                        tgt_mask=tgt_mask,\n",
        "                        tgt_key_padding_mask=(tgt_tensor == pad_id),\n",
        "                        memory_key_padding_mask=(src_tensor == pad_id))\n",
        "\n",
        "            # project to vocab and take highest‐scoring token\n",
        "            logits = model.output_layer(x)  # [1, T, vocab_size]\n",
        "            next_id = logits[0, len(tgt_ids)-1].argmax().item()\n",
        "            tgt_ids.append(next_id)\n",
        "            # stop generating tokens from decoder if this is met\n",
        "            if next_id == eos_id:\n",
        "                break\n",
        "\n",
        "        # drop the initial <s> and any padding\n",
        "        return tokenizer.decode(\n",
        "            [tid for tid in tgt_ids[1:] if tid not in {pad_id, eos_id}],\n",
        "            out_type=str\n",
        "        )\n"
      ],
      "metadata": {
        "id": "FlYgNcouT7hk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = TranslationDataset(test_en, test_it, tokenizer, max_len)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "# we use shuffle=False so we can reproduce the same tests"
      ],
      "metadata": {
        "id": "_Cpm069PCPr6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run test loop"
      ],
      "metadata": {
        "id": "srKus0IGa95G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds, all_refs = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        src = batch['src'].to(device)\n",
        "        tgt = batch['tgt'].to(device)\n",
        "        tgt_input, tgt_output = tgt[:,:-1], tgt[:,1:]\n",
        "\n",
        "        # run model, compute loss as before\n",
        "        for i in range(src.size(0)):\n",
        "\n",
        "            # decode and clean up the source: we do this for convenience, so\n",
        "            # you can call inference on a model and a string.\n",
        "            raw_src_ids = src[i].tolist()\n",
        "            src_ids = [tid for tid in raw_src_ids if tid != pad_id]\n",
        "            src_text = tokenizer.decode(src_ids, out_type=str)\n",
        "\n",
        "            # run inference, aka, translate the sentance\n",
        "            pred = inference(model, src_text, tokenizer, max_len)\n",
        "            all_preds.append(pred)\n",
        "\n",
        "            # build the reference string from tgt_output:\n",
        "            raw_ref_ids = tgt_output[i].tolist()\n",
        "            ref_ids = [tid for tid in raw_ref_ids if tid not in {pad_id, eos_id}]\n",
        "            ref = tokenizer.decode(ref_ids, out_type=str)\n",
        "            all_refs.append(ref)"
      ],
      "metadata": {
        "id": "Qp-jkpy6N9LN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds = np.array(all_preds)\n",
        "all_refs = np.array(all_refs)\n",
        "all_preds.shape, all_refs.shape"
      ],
      "metadata": {
        "id": "UwMcKONwtd8k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "994c5331-fa54-46db-d734-5b8bf29b2f6c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5000,), (5000,))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ok so now we have our predictions, we need to measure how good they are."
      ],
      "metadata": {
        "id": "s7uVT-15vA-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bleu\n",
        "bleu = sacrebleu.corpus_bleu(all_preds.tolist(), [all_refs.tolist()])\n",
        "print(f\"Test BLEU = {bleu.score:.2f}\")"
      ],
      "metadata": {
        "id": "5G0cx3Qou_Rc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aa0ce67-62ca-45ac-88cb-611bd0ddb36e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test BLEU = 16.12\n"
          ]
        }
      ]
    }
  ]
}